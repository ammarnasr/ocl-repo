# CLIP prefix captioning.

<a href="https://opensource.org/licenses/MIT"><img src="https://img.shields.io/badge/License-MIT-blue.svg"></a>  
Demo Notebook: <a href="https://colab.research.google.com/drive/1T5IFpdhlQmNvLufcepsfSjAn3gvtOcf8?usp=sharing"><img src="https://colab.research.google.com/assets/colab-badge.svg" height=20></a>  


<!-- to make text bols -->



##  *Training with single class images and Generalizing for multi-class images using Kasami Orthogonal Classification Layer* 

## Summary  
A Kasami Orthogonal Classification Layer (KOCL) for classification networks consists of a fully connected layer (just like a conventional 
classification/output layer) but with fixed non-trainable weights that are equal to a set of orthogonal Kasami codes. Each Kasami code among the set is assigned to one of the output neurons of the classification/output layer. 

Benefitting from the orthogonal properties of Kasami codes, and considering that latent representations generated by the network for a data point that belongs to more than one class can be approximated as the sum of the individual latent representations learned during training for all the classes present in this multi-label data point, we trained neural networks only on single label images then tested it with multi-label images without additional multi-label training.
